{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"demonstration.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"658F-8LMJTbs"},"source":["Download libraries and Initialise spark session"]},{"cell_type":"code","metadata":{"id":"upWP26joJCw2","executionInfo":{"status":"ok","timestamp":1622804935020,"user_tz":-330,"elapsed":58948,"user":{"displayName":"SHUBHAM KUMAR","photoUrl":"","userId":"00108614289856003661"}}},"source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q https://mirrors.estointernet.in/apache/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\n","!tar xf /content/spark-3.1.1-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\"\n","\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"llsi3L5NJ1-z"},"source":["Download dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cgu9YR5nJh1G","executionInfo":{"status":"ok","timestamp":1622804936651,"user_tz":-330,"elapsed":1654,"user":{"displayName":"SHUBHAM KUMAR","photoUrl":"","userId":"00108614289856003661"}},"outputId":"9eadf87c-f8d3-431f-e9e2-05da30ec111d"},"source":["!curl -L http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Musical_Instruments_5.json.gz -o data.json.gz"],"execution_count":2,"outputs":[{"output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 2402k  100 2402k    0     0  2479k      0 --:--:-- --:--:-- --:--:-- 2477k\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XekwxJI8J4UF"},"source":["Spark specific imports"]},{"cell_type":"code","metadata":{"id":"FcOxgz_1JqKN","executionInfo":{"status":"ok","timestamp":1622804936652,"user_tz":-330,"elapsed":6,"user":{"displayName":"SHUBHAM KUMAR","photoUrl":"","userId":"00108614289856003661"}}},"source":["from pyspark.ml.evaluation import RegressionEvaluator\n","from pyspark.ml.recommendation import ALS\n","from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n","from pyspark.ml.feature import StringIndexer\n","from pyspark.sql.functions import col\n","from pyspark.ml.evaluation import RegressionEvaluator\n","from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tJ_JMgjULWCv"},"source":["We train and test our sentiment analysis model on musical instruments dataset and use the model on a separate but similar amazon review dataset for demonstration purposes "]},{"cell_type":"markdown","metadata":{"id":"QidkjrvNMIob"},"source":["Read and display dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sVqAP5apKsnB","executionInfo":{"status":"ok","timestamp":1622804943269,"user_tz":-330,"elapsed":6622,"user":{"displayName":"SHUBHAM KUMAR","photoUrl":"","userId":"00108614289856003661"}},"outputId":"feaaa368-322d-4eea-ff32-8eb0a74a0337"},"source":["data = spark.read.json('data.json.gz')\n","data = data.select('overall','reviewText')\n","data = data.withColumnRenamed('overall', 'label')\n","data.show(5)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["+-----+--------------------+\n","|label|          reviewText|\n","+-----+--------------------+\n","|  5.0|Not much to write...|\n","|  5.0|The product does ...|\n","|  5.0|The primary job o...|\n","|  5.0|Nice windscreen p...|\n","|  5.0|This pop filter i...|\n","+-----+--------------------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_bOtZFliPEDp"},"source":["## **Sentiment Analysis**"]},{"cell_type":"code","metadata":{"id":"CFc-Ti95MMLj","executionInfo":{"status":"ok","timestamp":1622804945026,"user_tz":-330,"elapsed":1768,"user":{"displayName":"SHUBHAM KUMAR","photoUrl":"","userId":"00108614289856003661"}}},"source":["from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n","from pyspark.ml.feature import HashingTF, IDF\n","\n","# we tokenize review text column in dataset to split review text by words\n","regexTokenizer = RegexTokenizer(inputCol=\"reviewText\", outputCol=\"words\", pattern=\"\\\\W\")\n","'''\n","we use standard list of stopwords available in spark, note that we use the\n","input from regex tokenizer which splits string into words\n","'''\n","stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n","\n","'''\n","After removing stopwords, we use the filtered column to convert list of words\n","into raw features basically it means that given a list of words as\n","filtered = [I, saw, the, red, balloon,I,am,human] \n","It is converted into a vector of **fixed-size**\n","for the above example if 'I' is hashed to 24 ,then vector[24]=2 just stores the \n","frequency of 'I'\n","This fixed size by default is 2^18   \n","'''\n","hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\")\n","'''\n","minDocFreq: remove sparse terms\n","IDF is used to remove importance of words which occur often in document\n","refer : https://spark.apache.org/docs/latest/ml-features#feature-extractors\n","'''\n","idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) "],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Mr2KRXog1KF"},"source":["Setup pipeline and transform the data"]},{"cell_type":"code","metadata":{"id":"SJbUhQ6Dgvyi","executionInfo":{"status":"ok","timestamp":1622804950076,"user_tz":-330,"elapsed":5060,"user":{"displayName":"SHUBHAM KUMAR","photoUrl":"","userId":"00108614289856003661"}}},"source":["from pyspark.ml import Pipeline\n","\n","pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf])\n","pipelineFit = pipeline.fit(data)\n","dataset = pipelineFit.transform(data)\n","\n","(trainingData, testData) = dataset.randomSplit([0.8, 0.2])"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dd3vILzqhYqN"},"source":["Train logistic regression classifier on the data and find predictions for test data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6LhfkrlxhfMW","executionInfo":{"status":"ok","timestamp":1622804980551,"user_tz":-330,"elapsed":30488,"user":{"displayName":"SHUBHAM KUMAR","photoUrl":"","userId":"00108614289856003661"}},"outputId":"ddb70e46-e30a-4d86-af66-03da3f9c0e02"},"source":["from pyspark.ml.classification import LogisticRegression\n"," \n","# parameters can be tuned\n","lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n","lrModel = lr.fit(trainingData)\n","# find predictions\n","predictions = lrModel.transform(testData)\n","predictions.show(n=1, truncate=True, vertical=True)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["-RECORD 0-----------------------------\n"," label         | 1.0                  \n"," reviewText    | ...what is the so... \n"," words         | [what, is, the, s... \n"," filtered      | [sound, backgroun... \n"," rawFeatures   | (262144,[4714,744... \n"," features      | (262144,[4714,744... \n"," rawPrediction | [-5.5069815393259... \n"," probability   | [2.20309578445644... \n"," prediction    | 3.0                  \n","only showing top 1 row\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YtomSF_NhvLL"},"source":["Evaluate the results of LR model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HAJw0B4MhxEA","executionInfo":{"status":"ok","timestamp":1622804984791,"user_tz":-330,"elapsed":4275,"user":{"displayName":"SHUBHAM KUMAR","photoUrl":"","userId":"00108614289856003661"}},"outputId":"f512f530-331d-47e6-88c0-0b42fbce38a5"},"source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","\n","evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n","evaluator.evaluate(predictions)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5992091221281566"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"EkcV2gl4jKlV"},"source":["## **ALS Matrix factorization**\n"," \n","Note that different dataset is used here namely the Amazon digital music dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GY8mcucXivnY","executionInfo":{"status":"ok","timestamp":1622804985419,"user_tz":-330,"elapsed":638,"user":{"displayName":"SHUBHAM KUMAR","photoUrl":"","userId":"00108614289856003661"}},"outputId":"3b7b4b03-946e-49a3-ee2f-5b6ca4f740d9"},"source":["!curl -L http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Musical_Instruments_5.json.gz -o data_als.json.gz"],"execution_count":9,"outputs":[{"output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 2402k  100 2402k    0     0  2696k      0 --:--:-- --:--:-- --:--:-- 2696k\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4aTg_mD3TUK2"},"source":["Pre-processing data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GfaONen3qdOD","executionInfo":{"status":"ok","timestamp":1622804987722,"user_tz":-330,"elapsed":2309,"user":{"displayName":"SHUBHAM KUMAR","photoUrl":"","userId":"00108614289856003661"}},"outputId":"250a60d1-3333-4789-e0e4-a191511c0340"},"source":["df = spark.read.json('data_als.json.gz')\n","# only select the necessary rows\n","df = df.select('asin','overall','reviewText','reviewerID','helpful')\n","# Convert unique strings to integer using StringIndexer\n","asin_indexer = StringIndexer(inputCol=\"asin\", outputCol=\"itemId\")\n","reviewerID_indexer = StringIndexer(inputCol=\"reviewerID\", outputCol=\"userId\")\n","\n","df = asin_indexer.fit(df).transform(df)\n","df = reviewerID_indexer.fit(df).transform(df)\n","\n","# drop unnecessary columns \n","df = df.select('userId','itemId','reviewText','overall','helpful')\n","df = df.withColumnRenamed('overall', 'orig_rating')\n","\n","df.show(5)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["+------+------+--------------------+-----------+--------+\n","|userId|itemId|          reviewText|orig_rating| helpful|\n","+------+------+--------------------+-----------+--------+\n","|  66.0| 703.0|Not much to write...|        5.0|  [0, 0]|\n","| 266.0| 703.0|The product does ...|        5.0|[13, 14]|\n","| 395.0| 703.0|The primary job o...|        5.0|  [1, 1]|\n","|1048.0| 703.0|Nice windscreen p...|        5.0|  [0, 0]|\n","|1311.0| 703.0|This pop filter i...|        5.0|  [0, 0]|\n","+------+------+--------------------+-----------+--------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"F2II07ONTYrl"},"source":["Transform the data using the pipeline used earlier,\n","and calculate rating predicted by our sentiment classifcation model(*sent_rating*)"]},{"cell_type":"code","metadata":{"id":"4EORTYz0t-XW","executionInfo":{"status":"ok","timestamp":1622804987723,"user_tz":-330,"elapsed":42,"user":{"displayName":"SHUBHAM KUMAR","photoUrl":"","userId":"00108614289856003661"}}},"source":["df = pipelineFit.transform(df)\n","df = lrModel.transform(df)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jk0-hXr_HfVm","executionInfo":{"status":"ok","timestamp":1622804988098,"user_tz":-330,"elapsed":413,"user":{"displayName":"SHUBHAM KUMAR","photoUrl":"","userId":"00108614289856003661"}},"outputId":"af596e1c-80e7-4e1b-a672-652c8d0c76de"},"source":["# remove unnecessary columns\n","df = df.select('userId','itemId','orig_rating','helpful','prediction')\n","df = df.withColumnRenamed('prediction', 'sent_rating')\n","\n","df.show(2)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["+------+------+-----------+--------+-----------+\n","|userId|itemId|orig_rating| helpful|sent_rating|\n","+------+------+-----------+--------+-----------+\n","|  66.0| 703.0|        5.0|  [0, 0]|        5.0|\n","| 266.0| 703.0|        5.0|[13, 14]|        5.0|\n","+------+------+-----------+--------+-----------+\n","only showing top 2 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MdDqQmFhOwUi"},"source":["### **Normalising rating** - \n","\n","\n","Using formula -\n","\n","> orig_rating * 0.8 + sent_rating * 0.2 + overall_effect\n","\n","Where overall_effect is calculated as \n"," \n","```\n","  if pos > neg :\n","    overall_effect = 1+(pos)/(pos+neg)\n","  else :\n","    overall_effect = 1-(neg)/(pos+neg)\n","  \n","  overall_effect *= 0.5\n","```\n","Where \n","\n",">  pos = number of people who found that review helpful \\\n","neg = number of people who found that review not-helpful\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"62EVJ6CHxokc","executionInfo":{"status":"ok","timestamp":1622804988100,"user_tz":-330,"elapsed":12,"user":{"displayName":"SHUBHAM KUMAR","photoUrl":"","userId":"00108614289856003661"}}},"source":["from pyspark.sql.functions import udf,col\n","from pyspark.sql.types import DoubleType\n","\n","def normalise_rating(orig_rating,sent_rating,helpful):\n","  # return helpful[0]\n","  pos = helpful[0]+1\n","  neg = helpful[1]+1\n","  \n","  if pos > neg :\n","    effect = 1+(pos)/(pos+neg)\n","  else :\n","    effect = 1-(neg)/(pos+neg)\n","  \n","  effect *= 0.5\n","\n","  return effect+orig_rating*0.8+sent_rating*0.2\n","  \n","# register it as a spark user-defined function with double return type\n","normalise_udf = udf(normalise_rating,DoubleType())"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ffWT7gnBYL4","executionInfo":{"status":"ok","timestamp":1622804991850,"user_tz":-330,"elapsed":3760,"user":{"displayName":"SHUBHAM KUMAR","photoUrl":"","userId":"00108614289856003661"}},"outputId":"19879ca6-1a1c-420f-8a1a-dab30760713d"},"source":["# Normalise the rating and store result in df2\n","\n","df2 = df.withColumn(\"norm_rating\", normalise_udf(col(\"orig_rating\"),col(\"sent_rating\"),col(\"helpful\")))\n","df2.show(5)\n","df2.printSchema()\n","\n","# split data into train-test\n","(train, test) = df2.randomSplit([0.8, 0.2], seed = 1234)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["+------+------+-----------+--------+-----------+-----------------+\n","|userId|itemId|orig_rating| helpful|sent_rating|      norm_rating|\n","+------+------+-----------+--------+-----------+-----------------+\n","|  66.0| 703.0|        5.0|  [0, 0]|        5.0|             5.25|\n","| 266.0| 703.0|        5.0|[13, 14]|        5.0|5.241379310344827|\n","| 395.0| 703.0|        5.0|  [1, 1]|        5.0|             5.25|\n","|1048.0| 703.0|        5.0|  [0, 0]|        4.0|             5.05|\n","|1311.0| 703.0|        5.0|  [0, 0]|        5.0|             5.25|\n","+------+------+-----------+--------+-----------+-----------------+\n","only showing top 5 rows\n","\n","root\n"," |-- userId: double (nullable = false)\n"," |-- itemId: double (nullable = false)\n"," |-- orig_rating: double (nullable = true)\n"," |-- helpful: array (nullable = true)\n"," |    |-- element: long (containsNull = true)\n"," |-- sent_rating: double (nullable = false)\n"," |-- norm_rating: double (nullable = true)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2_QKINvmMS6E"},"source":["Run ALS on 3 rating columns we have obtained \n","\n","\n","1.   orig_rating = original rating given by user\n","2.   sent_rating = rating obtained by using LR sentiment analysis\n","3. norm_rating = normalised rating caluclated by us, using the orig_rating,sent_rating,helpfulness where more helpful ratings of more helpful reviews are increased and weighted average of orig_rating and sent_rating is \n","\n"]},{"cell_type":"code","metadata":{"id":"VnxOlrsbIkib","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622805075031,"user_tz":-330,"elapsed":83187,"user":{"displayName":"SHUBHAM KUMAR","photoUrl":"","userId":"00108614289856003661"}},"outputId":"19002eba-06c7-4077-a084-36a40541c490"},"source":["rating_columns = ['orig_rating','norm_rating']\n","\n","# using each of the rating columns run ALS matrix factorization and obtain RMSE\n","\n","for rating_column in rating_columns:\n","\n","  als = ALS(maxIter=20, regParam=0.1, rank=50,userCol=\"userId\", itemCol=\"itemId\", ratingCol=rating_column,coldStartStrategy=\"drop\")\n","  model = als.fit(train)\n","\n","  # Evaluate the model by computing the RMSE on the test data\n","  predictions = model.transform(test)\n","  evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=rating_column,predictionCol=\"prediction\")\n","  rmse = evaluator.evaluate(predictions)\n","  print(f\"For {rating_column} Root-mean-square error = {rmse}\")\n"],"execution_count":15,"outputs":[{"output_type":"stream","text":["For orig_rating Root-mean-square error = 1.096972208241755\n","For norm_rating Root-mean-square error = 0.9640859879724919\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CMYgtDFrJYzl","executionInfo":{"status":"ok","timestamp":1622805075033,"user_tz":-330,"elapsed":32,"user":{"displayName":"SHUBHAM KUMAR","photoUrl":"","userId":"00108614289856003661"}}},"source":[""],"execution_count":15,"outputs":[]}]}